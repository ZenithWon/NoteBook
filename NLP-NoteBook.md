## ChatGPT

#### 训练原理

1. pre-train模型：GPT，generative pre-train transformer。

   预训练任务：多个decoder堆叠，做下一个词的预测
   
2. supervised learning：QA问答，有专家制作labeled数据

3. reinforcement learning：由于一些问题没有绝对正确和绝对错误（如写一首诗），因此可以通过专家打分给出reward，进行RL

#### 前景

1. prompt工程
2. neural editing
3. discriminate AI generating
4. machine unlearing